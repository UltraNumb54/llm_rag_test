import torch
from transformers import (
    AutoTokenizer, 
    AutoModelForTokenClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForTokenClassification
)
from datasets import Dataset, load_from_disk
import json
import numpy as np
from seqeval.metrics import classification_report, f1_score, precision_score, recall_score
import logging
import os
from datetime import datetime

# Настройка логирования
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RuBertNERTrainer:
    def __init__(self, model_name="DeepPavlov/rubert-base-cased"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
    def load_data(self, dataset_path="./processed_ner_dataset"):
        """Загрузка предобработанных данных"""
        try:
            self.dataset = load_from_disk(dataset_path)
            
            # Загрузка маппинга меток
            with open("label_mapping.json", "r") as f:
                self.label_mapping = json.load(f)
            
            # Создаем id2label и label2id
            self.id2label = {int(v): k for k, v in self.label_mapping.items()}
            self.label2id = {k: int(v) for k, v in self.label_mapping.items()}
            
            self.label_names = list(self.label_mapping.keys())
            self.num_labels = len(self.label_names)
            
            logger.info(f"Загружено {len(self.dataset)} примеров")
            logger.info(f"Метки: {self.label_names}")
            logger.info(f"Label mapping: {self.label_mapping}")
            
            # Разделение на train/validation если не разделено
            if "train" not in self.dataset:
                self.dataset = self.dataset.train_test_split(test_size=0.1, seed=42)
                logger.info(f"Данные разделены: train={len(self.dataset['train'])}, test={len(self.dataset['test'])}")
            
            return self.dataset
            
        except Exception as e:
            logger.error(f"Ошибка загрузки данных: {e}")
            raise
    
    def compute_metrics(self, eval_pred):
        """Вычисление метрик для NER"""
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=2)
        
        # Удаляем специальные токены (метка -100)
        true_predictions = []
        true_labels = []
        
        for i in range(len(predictions)):
            preds = []
            lbls = []
            for j in range(len(predictions[i])):
                if labels[i][j] != -100:  # Игнорируем padding и специальные токены
                    preds.append(self.id2label.get(predictions[i][j], "O"))
                    lbls.append(self.id2label.get(labels[i][j], "O"))
            true_predictions.append(preds)
            true_labels.append(lbls)
        
        # Вычисляем метрики
        precision = precision_score(true_labels, true_predictions, zero_division=0)
        recall = recall_score(true_labels, true_predictions, zero_division=0)
        f1 = f1_score(true_labels, true_predictions, zero_division=0)
        
        # Детальный отчет (логируем только в конце)
        if hasattr(self, 'log_detailed_report'):
            report = classification_report(true_labels, true_predictions, output_dict=True, zero_division=0)
        else:
            report = {}
        
        return {
            "precision": precision,
            "recall": recall,
            "f1": f1,
        }
    
    def train(self, output_dir="./rubert_ner_model"):
        """Обучение модели"""
        
        logger.info(f"Загрузка модели: {self.model_name}")
        
        # Загрузка модели
        model = AutoModelForTokenClassification.from_pretrained(
            self.model_name,
            num_labels=self.num_labels,
            id2label=self.id2label,
            label2id=self.label2id,
            ignore_mismatched_sizes=True
        )
        
        # Проверяем доступность GPU
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        logger.info(f"Используется устройство: {device}")
        
        if torch.cuda.is_available():
            logger.info(f"GPU память: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # Аргументы обучения (адаптированы под большую модель)
        training_args = TrainingArguments(
            output_dir=output_dir,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            learning_rate=3e-5,  # Немного меньше learning rate для большей модели
            per_device_train_batch_size=8,   # Уменьшили batch size для rubert-base
            per_device_eval_batch_size=8,
            num_train_epochs=4,
            weight_decay=0.01,
            warmup_steps=500,
            logging_dir='./logs',
            logging_steps=50,
            save_total_limit=2,
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            push_to_hub=False,
            report_to=None,
            dataloader_pin_memory=False,
            gradient_accumulation_steps=2,  # Эмулируем больший batch size
            eval_accumulation_steps=1,
            fp16=torch.cuda.is_available(),  # Используем mixed precision если есть GPU
        )
        
        # Data collator для динамического паддинга
        data_collator = DataCollatorForTokenClassification(
            tokenizer=self.tokenizer,
            padding=True,
            max_length=512,
        )
        
        # Создание тренера
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=self.dataset["train"],
            eval_dataset=self.dataset["test"],
            tokenizer=self.tokenizer,
            data_collator=data_collator,
            compute_metrics=self.compute_metrics,
        )
        
        # Запуск обучения
        logger.info("Начало обучения...")
        start_time = datetime.now()
        
        train_result = trainer.train()
        
        training_time = datetime.now() - start_time
        logger.info(f"Обучение завершено за {training_time}")
        
        # Сохранение модели и токенизатора
        trainer.save_model(output_dir)
        self.tokenizer.save_pretrained(output_dir)
        
        # Сохранение метрик
        metrics = train_result.metrics
        logger.info(f"Финальные метрики: {metrics}")
        
        # Детальная оценка в конце
        self.log_detailed_report = True
        eval_metrics = trainer.evaluate()
        logger.info(f"Финальная оценка: {eval_metrics}")
        
        logger.info(f"Модель сохранена в {output_dir}")
        
        return trainer

def main():
    try:
        # Инициализация тренера с выбранной моделью
        trainer = RuBertNERTrainer("DeepPavlov/rubert-base-cased")
        
        # Загрузка данных
        trainer.load_data()
        
        # Обучение
        trainer.train("./rubert_custom_ner_model")
        
    except Exception as e:
        logger.error(f"Ошибка в основном процессе: {e}")
        raise

if __name__ == "__main__":
    main()
