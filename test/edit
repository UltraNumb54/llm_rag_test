1. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/config.py
from typing import List, Optional
from pydantic import Field, validator
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞
    HOST: str = "0.0.0.0"
    PORT: int = 8000

    # –ú–æ–¥–µ–ª–∏ –¥–ª—è embedding –∏ —Ä–µ—Ä–∞–Ω–∫–µ—Ä–∞
    EMBEDDING_MODEL: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    RERANKER_MODEL: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ vLLM
    VLLM_BASE_URL: str = "http://localhost:8000/v1"
    VLLM_API_KEY: str = "none"
    VLLM_MODEL_NAME: str = "Qwen/Qwen2.5-7B-Instruct-AWQ"

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL
    DATABASE_URL: str = "postgresql://rag_user:password@localhost:5432/rag_db"
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    CHUNK_SIZE: int = 500
    CHUNK_OVERLAP: int = 50
    MAX_FILE_SIZE: int = 100 * 1024 * 1024  # 100MB

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞
    TOP_K: int = 3
    RERANK_TOP_K: int = 2
    MAX_CONCURRENT_REQUESTS: int = 10

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    API_KEY: Optional[str] = None
    CORS_ORIGINS: List[str] = Field(default_factory=lambda: ["*"])

    @validator("DATABASE_URL")
    def validate_database_url(cls, v):
        if not v.startswith("postgresql://"):
            raise ValueError("DATABASE_URL must start with postgresql://")
        return v

    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()

2. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/core/database.py
import asyncpg
import numpy as np
from app.config import settings
from loguru import logger

class DatabaseManager:
    _pool = None

    @classmethod
    async def get_pool(cls):
        if cls._pool is None:
            try:
                cls._pool = await asyncpg.create_pool(
                    settings.DATABASE_URL,
                    min_size=5,
                    max_size=20,
                    command_timeout=60
                )
                logger.info("PostgreSQL connection pool created successfully")
                
                # Initialize database schema
                await cls._init_schema()
                
            except Exception as e:
                logger.error(f"Failed to create database connection pool: {e}")
                raise
        return cls._pool

    @classmethod
    async def _init_schema(cls):
        """Initialize database tables and indexes"""
        pool = await cls.get_pool()
        async with pool.acquire() as conn:
            # Enable vector extension
            await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            
            # Create documents table
            await conn.execute('''
                CREATE TABLE IF NOT EXISTS documents (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    content TEXT NOT NULL,
                    embedding VECTOR(384), -- —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è multilingual-MiniLM-L12-v2
                    metadata JSONB DEFAULT '{}',
                    created_at TIMESTAMPTZ DEFAULT NOW(),
                    updated_at TIMESTAMPTZ DEFAULT NOW()
                );
            ''')
            
            # Create index for vector search
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS documents_embedding_idx 
                ON documents USING ivfflat (embedding vector_cosine_ops)
                WITH (lists = 100);
            ''')
            
            # Create metadata index
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS documents_metadata_idx 
                ON documents USING gin (metadata);
            ''')
            
            logger.info("Database schema initialized successfully")

    @classmethod
    async def close_pool(cls):
        if cls._pool:
            await cls._pool.close()
            cls._pool = None
            logger.info("Database connection pool closed")

# Utility functions
async def get_database_pool():
    return await DatabaseManager.get_pool()

async def init_database():
    await DatabaseManager.get_pool()

async def close_database():
    await DatabaseManager.close_pool()

3. –ù–æ–≤—ã–π app/services/vector_store.py —Å PostgreSQL
import uuid
from typing import Any, Dict, List, Optional
import numpy as np

from app.config import settings
from app.core.database import get_database_pool
from app.services.embedding import embedding_service
from loguru import logger

class PGVectorStoreService:
    def __init__(self):
        self.embedding_dim = 384  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è multilingual-MiniLM-L12-v2
        self.pool = None

    async def init(self):
        """Initialize connection pool"""
        self.pool = await get_database_pool()

    async def add_documents(
        self, documents: List[str], metadatas: List[Dict[str, Any]] = None
    ) -> List[str]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ PostgreSQL"""
        if not documents:
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return []

        if metadatas is None:
            metadatas = [{}] * len(documents)
        elif len(metadatas) != len(documents):
            logger.warning("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            metadatas = [{}] * len(documents)

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            embeddings = embedding_service.encode(documents)

            ids = []
            async with self.pool.acquire() as conn:
                for i, (doc, embedding, metadata) in enumerate(zip(documents, embeddings, metadatas)):
                    doc_id = str(uuid.uuid4())
                    # Convert embedding to PostgreSQL vector format
                    embedding_vector = f"[{','.join(map(str, embedding))}]"
                    
                    await conn.execute('''
                        INSERT INTO documents (id, content, embedding, metadata)
                        VALUES ($1, $2, $3::vector, $4)
                    ''', doc_id, doc, embedding_vector, metadata)
                    
                    ids.append(doc_id)

            logger.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL")
            return ids

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL: {e}")
            raise

    async def search(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL"""
        if top_k is None:
            top_k = settings.TOP_K

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = embedding_service.encode(query)
            query_vector = f"[{','.join(map(str, query_embedding))}]"

            async with self.pool.acquire() as conn:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                results = await conn.fetch('''
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> $1::vector) as similarity
                    FROM documents
                    ORDER BY embedding <=> $1::vector
                    LIMIT $2
                ''', query_vector, top_k)

                formatted_results = []
                for row in results:
                    formatted_results.append({
                        "id": row["id"],
                        "document": row["content"],
                        "metadata": row["metadata"] or {},
                        "distance": 1 - float(row["similarity"]),
                        "score": float(row["similarity"])
                    })

                logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(formatted_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                return formatted_results

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ PostgreSQL: {e}")
            return []

    async def get_collection_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            async with self.pool.acquire() as conn:
                count = await conn.fetchval("SELECT COUNT(*) FROM documents")
                return {
                    "database": "PostgreSQL",
                    "table_name": "documents",
                    "document_count": count,
                    "status": "healthy",
                    "vector_dimension": self.embedding_dim
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return {
                "database": "PostgreSQL",
                "table_name": "documents",
                "document_count": 0,
                "status": "error",
                "error": str(e)
            }

    async def delete_all_documents(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("DELETE FROM documents")
                logger.info("–í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —É–¥–∞–ª–µ–Ω—ã –∏–∑ PostgreSQL")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            raise

# Global instance
vector_store = PGVectorStoreService()
4. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/main.py
import os
import sys
import uvicorn
import asyncio
from contextlib import asynccontextmanager

from app.config import settings
from app.core.database import init_database, close_database
from app.services.vector_store import vector_store
from app.services.vllm_manager import vllm_manager, cleanup_all_vllm_processes
from app.utils.logger import setup_logger
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

# Import routers
from app.routers import health, chat, files

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await init_database()
    await vector_store.init()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º vLLM —Å–µ—Ä–≤–µ—Ä
    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è vLLM —Å–µ—Ä–≤–µ—Ä–∞...")
    if not vllm_manager.start_vllm_server():
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å vLLM —Å–µ—Ä–≤–µ—Ä. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
        raise RuntimeError("VLLM server failed to start")
    
    yield
    
    # Shutdown
    vllm_manager.stop_vllm_server()
    cleanup_all_vllm_processes()
    await close_database()

app = FastAPI(
    title="RAG System with vLLM",
    description="–°–∏—Å—Ç–µ–º–∞ RAG —Å vLLM –∏ PostgreSQL –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# Include routers
app.include_router(health.router, prefix="/api/v1", tags=["health"])
app.include_router(chat.router, prefix="/api/v1", tags=["chat"])
app.include_router(files.router, prefix="/api/v1", tags=["files"])

@app.get("/")
async def root():
    return {"message": "RAG System with vLLM and PostgreSQL", "status": "running"}

@app.get("/api/v1")
async def api_info():
    return {
        "name": "RAG API",
        "version": "1.0.0",
        "models": {
            "llm": settings.VLLM_MODEL_NAME,
            "embedding": settings.EMBEDDING_MODEL,
            "reranker": settings.RERANKER_MODEL
        }
    }

def setup_environment():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    os.makedirs("uploads", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    os.makedirs("static", exist_ok=True)

def print_startup_info():
    """–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—É—Å–∫–µ"""
    print("\n" + "="*60)
    print("üöÄ –ó–∞–ø—É—Å–∫ RAG —Å–∏—Å—Ç–µ–º—ã —Å vLLM –∏ PostgreSQL")
    print("="*60)
    print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"- –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://{settings.HOST}:{settings.PORT}")
    print(f"- API: http://{settings.HOST}:{settings.PORT}/api/v1")
    print(f"- vLLM —Å–µ—Ä–≤–µ—Ä: {settings.VLLM_BASE_URL}")
    print(f"- –ú–æ–¥–µ–ª—å: {settings.VLLM_MODEL_NAME}")
    print(f"- –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: PostgreSQL —Å pgvector")
    print(f"- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://{settings.HOST}:{settings.PORT}/docs")
    print()
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ endpoints:")
    print("GET  /                   - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ API")
    print("   POST /api/v1/upload      - –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
    print("   POST /api/v1/chat        - –ß–∞—Ç —Å RAG")
    print("   GET  /api/v1/health      - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    print("="*60)
    print()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
    setup_environment()
    setup_logger()
    
    print_startup_info()

    try:
        uvicorn.run(
            "app.main:app",
            host=settings.HOST,
            port=settings.PORT,
            reload=True,
            log_level="info",
            access_log=True,
        )
    except KeyboardInterrupt:
        print("\n–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è...")
    except Exception as e:
        print(f"\n–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        print("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    main()
5. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/routers/health.py
python
import os
import psutil
import asyncpg
from app.config import settings
from app.core.database import get_database_pool
from app.services.llm_service import llm_service
from fastapi import APIRouter, HTTPException
from loguru import logger

router = APIRouter()

@router.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
    checks = {}

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ PostgreSQL
    try:
        pool = await get_database_pool()
        async with pool.acquire() as conn:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ vector
            await conn.fetchval("SELECT 1")
            vector_ext = await conn.fetchval(
                "SELECT installed_version FROM pg_available_extensions WHERE name = 'vector'"
            )
            checks["postgresql"] = {
                "status": "healthy", 
                "message": "Connected with vector extension",
                "vector_version": vector_ext
            }
    except Exception as e:
        checks["postgresql"] = {"status": "unhealthy", "message": str(e)}

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ vLLM
    try:
        test_response = llm_service.generate("–û—Ç–≤–µ—Ç—å 'OK'", max_tokens=5)
        checks["vllm"] = {
            "status": "healthy",
            "message": "Connected",
            "test_response": test_response.strip() if test_response else "No response"
        }
    except Exception as e:
        checks["vllm"] = {"status": "unhealthy", "message": str(e)}

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏
    memory = psutil.virtual_memory()
    checks["memory"] = {
        "total_gb": round(memory.total / (1024**3), 2),
        "available_gb": round(memory.available / (1024**3), 2),
        "used_percent": memory.percent,
    }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫–∞
    disk = psutil.disk_usage("/")
    checks["disk"] = {
        "total_gb": round(disk.total / (1024**3), 2),
        "free_gb": round(disk.free / (1024**3), 2),
        "used_percent": disk.percent,
    }

    # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
    critical_services_healthy = all(
        checks[service]["status"] == "healthy" for service in ["postgresql", "vllm"]
    )

    overall_status = "healthy" if critical_services_healthy else "degraded"

    return {
        "status": overall_status, 
        "version": "1.0.0", 
        "checks": checks
    }
6. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/routers/chat.py
python
from typing import List, Optional
from app.config import settings
from app.services.llm_service import llm_service
from app.services.reranker import reranker_service
from app.services.vector_store import vector_store
from fastapi import APIRouter, HTTPException
from loguru import logger
from pydantic import BaseModel, Field

router = APIRouter()

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤
conversation_store = {}

class ChatRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    use_reranking: bool = True

class ChatResponse(BaseModel):
    response: str = Field(default="")
    conversation_id: str = Field(default="default")
    sources: List[str] = Field(default_factory=list)
    suggested_questions: List[str] = Field(default_factory=list)

@router.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —á–∞—Ç–∞: {request.message}")

        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º ID –¥–∏–∞–ª–æ–≥–∞
        conversation_id = request.conversation_id or f"conv_{len(conversation_store) + 1}"

        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        history = conversation_store.get(conversation_id, [])

        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        search_results = await vector_store.search(request.message, top_k=settings.TOP_K)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(search_results)}")

        response_text = ""
        sources = []

        if not search_results:
            response_text = (
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å."
            )
            logger.info("–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç")
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            documents = [result["document"] for result in search_results]
            logger.info(f"–ü–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {documents[0][:100]}..." if documents else "–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            # –†–µ—Ä–∞–Ω–∫–∏–Ω–≥ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
            if request.use_reranking and len(documents) > 1:
                logger.info("–ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                reranked_docs = reranker_service.rerank(
                    request.message, documents, top_k=settings.RERANK_TOP_K
                )
                context_docs = [doc for doc, score in reranked_docs]
            else:
                context_docs = documents[: settings.RERANK_TOP_K]

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º...")
            response_text = llm_service.generate_with_context(
                question=request.message,
                context=context_docs,
                conversation_history=history,
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not response_text or response_text.strip() == "":
                response_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

            sources = [result["document"][:100] + "..." for result in search_results[:3]]

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        history.extend([
            {"role": "user", "content": request.message},
            {"role": "assistant", "content": response_text},
        ])

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 10 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        conversation_store[conversation_id] = history[-10:]

        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        suggested_questions = [
            "–ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å?",
            "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∏—Å–∫?",
            "–ö–∞–∫–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è?",
        ]

        logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤")

        return ChatResponse(
            response=response_text,
            conversation_id=conversation_id,
            sources=sources,
            suggested_questions=suggested_questions,
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —á–∞—Ç–µ: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")

@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞"""
    history = conversation_store.get(conversation_id, [])
    return {"conversation_id": conversation_id, "history": history}
7. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª app/routers/files.py
python
import os
import aiofiles
from typing import List
from fastapi import APIRouter, UploadFile, File, HTTPException
from app.services.file_processor import file_processor
from app.services.vector_store import vector_store
from loguru import logger

router = APIRouter()

@router.post("/upload")
async def upload_files(files: List[UploadFile] = File(...)):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"""
    uploaded_files = []
    processed_documents = []
    
    for file in files:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file.file.seek(0, 2)  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
            file_size = file.file.tell()
            file.file.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –Ω–∞—á–∞–ª–æ
            
            if file_size > 100 * 1024 * 1024:  # 100MB
                raise HTTPException(status_code=400, detail=f"–§–∞–π–ª {file.filename} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            file_path = f"uploads/{file.filename}"
            async with aiofiles.open(file_path, 'wb') as f:
                content = await file.read()
                await f.write(content)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
            documents = await file_processor.process_file(file_path)
            processed_documents.extend(documents)
            
            uploaded_files.append({
                "filename": file.filename,
                "size": file_size,
                "document_count": len(documents)
            })
            
            logger.info(f"–§–∞–π–ª {file.filename} –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file.filename}: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file.filename}: {str(e)}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    if processed_documents:
        document_ids = await vector_store.add_documents(processed_documents)
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(document_ids)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
    
    return {
        "message": f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(uploaded_files)} —Ñ–∞–π–ª–æ–≤",
        "uploaded_files": uploaded_files,
        "total_documents": len(processed_documents)
    }

@router.get("/files")
async def list_uploaded_files():
    """–°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        files = []
        if os.path.exists("uploads"):
            for filename in os.listdir("uploads"):
                file_path = os.path.join("uploads", filename)
                if os.path.isfile(file_path):
                    files.append({
                        "filename": filename,
                        "size": os.path.getsize(file_path),
                        "modified": os.path.getmtime(file_path)
                    })
        return {"files": files}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤")
8. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π requirements.txt
txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
loguru==0.7.2
asyncpg==0.29.0
sentence-transformers==2.2.2
transformers==4.35.2
torch==2.1.2
numpy==1.24.3
psutil==5.9.6
python-multipart==0.0.6
python-dotenv==1.0.0
aiofiles==23.2.1
requests==2.31.0
chromadb==0.4.22
openai==1.3.9

9. –°–æ–∑–¥–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î scripts/init_database.py
python
#!/usr/bin/env python3
import asyncio
import asyncpg
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.config import settings

async def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö postgres –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞—à–µ–π –ë–î
        conn = await asyncpg.connect(
            database="postgres",
            user="postgres",
            password="your_password_here",  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø–∞—Ä–æ–ª—å
            host="localhost"
        )
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await conn.execute("""
            CREATE USER rag_user WITH PASSWORD 'secure_password';
            CREATE DATABASE rag_db OWNER rag_user;
            GRANT ALL PRIVILEGES ON DATABASE rag_db TO rag_user;
        """)
        
        await conn.close()
        
        # –¢–µ–ø–µ—Ä—å –ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –Ω–æ–≤–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
        conn = await asyncpg.connect(settings.DATABASE_URL)
        
        # –í–∫–ª—é—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ vector
        await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
        
        print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        print(f"   URL: {settings.DATABASE_URL}")
        
        await conn.close()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(init_database())

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# –î–∞–π—Ç–µ –ø—Ä–∞–≤–∞ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞
chmod +x scripts/init_database.py

# –°–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–ª–∏)
sudo -u postgres createuser --createdb --createrole --superuser rag_user
sudo -u postgres createdb -O rag_user rag_db

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º psql
sudo -u postgres psql -c "CREATE USER rag_user WITH PASSWORD 'secure_password';"
sudo -u postgres psql -c "CREATE DATABASE rag_db OWNER rag_user;"
sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE rag_db TO rag_user;"

