vector

import uuid
import json
import math
from typing import Any, Dict, List, Optional
import numpy as np

from app.config import settings
from app.core.database import get_database_pool, is_database_initialized
from app.services.embedding import embedding_service
from loguru import logger

class PGVectorStoreService:
    def __init__(self):
        self.embedding_dim = embedding_service.embedding_dim
        self.pool = None
        self.initialized = False

    async def init(self):
        """Initialize connection pool"""
        try:
            if not is_database_initialized():
                logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö...")
                self.pool = await get_database_pool()
                self.initialized = True
                logger.info(f"Vector store service initialized with embedding dim: {self.embedding_dim}")
            else:
                self.pool = await get_database_pool()
                self.initialized = True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ vector store: {e}")
            raise

    async def ensure_connection(self):
        """–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ"""
        if not self.initialized or self.pool is None or self.pool._closed:
            logger.warning("–ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
            await self.init()

    def _prepare_embedding(self, embedding) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è PostgreSQL –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ pgvector"""
        if hasattr(embedding, 'tolist'):
            embedding_list = embedding.tolist()
        else:
            embedding_list = embedding

        # –ï—Å–ª–∏ —ç—Ç–æ —Å–∫–∞–ª—è—Ä, —Å–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        if isinstance(embedding_list, (int, float)):
            embedding_list = [float(embedding_list)] * self.embedding_dim
            logger.warning(f"–°–∫–∞–ª—è—Ä–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ä–∞—Å—à–∏—Ä–µ–Ω –¥–æ –≤–µ–∫—Ç–æ—Ä–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ {self.embedding_dim}")
        elif len(embedding_list) != self.embedding_dim:
            logger.warning(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ ({len(embedding_list)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–µ–º–æ–π ({self.embedding_dim})")
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            if len(embedding_list) > self.embedding_dim:
                embedding_list = embedding_list[:self.embedding_dim]
            else:
                embedding_list.extend([0.0] * (self.embedding_dim - len(embedding_list)))

        # –û—á–∏—â–∞–µ–º –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        cleaned_embedding = []
        for x in embedding_list:
            if isinstance(x, (int, float)) and not (math.isnan(x) or math.isinf(x)):
                cleaned_embedding.append(float(x))
            else:
                cleaned_embedding.append(0.0)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ pgvector: '[1.0,2.0,3.0]'
        vector_str = '[' + ','.join(map(str, cleaned_embedding)) + ']'
        return vector_str

    def _metadata_to_jsonb(self, metadata: Dict[str, Any]) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ JSON —Å—Ç—Ä–æ–∫—É –¥–ª—è PostgreSQL JSONB"""
        if metadata is None:
            return '{}'
        return json.dumps(metadata, ensure_ascii=False)

    async def add_documents(
        self, documents: List[str], metadatas: List[Dict[str, Any]] = None
    ) -> List[str]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ PostgreSQL"""
        if not documents:
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return []

        await self.ensure_connection()

        if metadatas is None:
            metadatas = [{}] * len(documents)
        elif len(metadatas) != len(documents):
            logger.warning("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            metadatas = [{}] * len(documents)

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            embeddings = embedding_service.encode(documents)

            ids = []
            async with self.pool.acquire() as conn:
                for i, (doc, embedding, metadata) in enumerate(zip(documents, embeddings, metadatas)):
                    doc_id = str(uuid.uuid4())
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                    prepared_embedding = self._prepare_embedding(embedding)
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON —Å—Ç—Ä–æ–∫—É
                    metadata_json = self._metadata_to_jsonb(metadata)
                    
                    # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø vector –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
                    await conn.execute('''
                        INSERT INTO documents (id, content, embedding, metadata)
                        VALUES ($1, $2, $3::vector, $4::jsonb)
                    ''', doc_id, doc, prepared_embedding, metadata_json)
                    
                    ids.append(doc_id)
                    
                    if (i + 1) % 10 == 0:
                        logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1}/{len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            logger.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL")
            return ids

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL: {e}")
            raise

    async def search(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL"""
        if top_k is None:
            top_k = settings.TOP_K

        await self.ensure_connection()

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query[:100]}...")
            query_embedding = embedding_service.encode(query)
            prepared_embedding = self._prepare_embedding(query_embedding)

            logger.debug(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞: {len(prepared_embedding.split(','))}")

            async with self.pool.acquire() as conn:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º —Ç–∏–ø–∞ vector
                results = await conn.fetch('''
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> $1::vector) as similarity
                    FROM documents
                    ORDER BY embedding <=> $1::vector
                    LIMIT $2
                ''', prepared_embedding, top_k)

                formatted_results = []
                for row in results:
                    formatted_results.append({
                        "id": str(row["id"]),
                        "document": row["content"],
                        "metadata": row["metadata"] or {},
                        "distance": 1 - float(row["similarity"]),
                        "score": float(row["similarity"])
                    })

                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(formatted_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                return formatted_results

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ PostgreSQL: {e}")
            return []

    async def get_collection_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        await self.ensure_connection()

        try:
            async with self.pool.acquire() as conn:
                count = await conn.fetchval("SELECT COUNT(*) FROM documents")
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                dim_info = await conn.fetchval("""
                    SELECT atttypmod FROM pg_attribute 
                    WHERE attrelid = 'documents'::regclass 
                    AND attname = 'embedding'
                """)
                
                return {
                    "database": "PostgreSQL",
                    "table_name": "documents",
                    "document_count": count,
                    "status": "healthy",
                    "vector_dimension": self.embedding_dim,
                    "actual_dimension": dim_info if dim_info else "unknown"
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return {
                "database": "PostgreSQL",
                "table_name": "documents",
                "document_count": 0,
                "status": "error",
                "error": str(e)
            }

    async def clear_collection(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        await self.ensure_connection()
        
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("DELETE FROM documents")
                logger.success("–ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—á–∏—â–µ–Ω–∞")
                return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return False

# Global instance
vector_store = PGVectorStoreService()

database

import asyncpg
from app.config import settings
from app.services.embedding import embedding_service
from loguru import logger

class DatabaseManager:
    _pool = None
    _initialized = False

    @classmethod
    async def get_pool(cls):
        if cls._pool is None or cls._pool._closed:
            try:
                cls._pool = await asyncpg.create_pool(
                    settings.DATABASE_URL,
                    min_size=5,
                    max_size=20,
                    command_timeout=60,
                    max_inactive_connection_lifetime=300
                )
                cls._initialized = True
                logger.info("PostgreSQL connection pool created successfully")
                
                # Initialize database schema
                await cls._init_schema()
                
            except Exception as e:
                logger.error(f"Failed to create database connection pool: {e}")
                raise
        return cls._pool

    @classmethod
    async def _init_schema(cls):
        """Initialize database tables and indexes"""
        pool = await cls.get_pool()
        async with pool.acquire() as conn:
            # Enable vector extension
            try:
                await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                logger.info("pgvector extension enabled successfully")
            except Exception as e:
                logger.error(f"Failed to enable vector extension: {e}")
                # –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
                raise

            # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ —Å–µ—Ä–≤–∏—Å–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embedding_dim = embedding_service.embedding_dim
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
            table_exists = await conn.fetchval("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = 'documents'
                );
            """)
            
            if table_exists:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç–∞–±–ª–∏—Ü—ã
                current_dim = await conn.fetchval("""
                    SELECT atttypmod FROM pg_attribute 
                    WHERE attrelid = 'documents'::regclass 
                    AND attname = 'embedding'
                """)
                
                # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ —Å –¥—Ä—É–≥–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é, –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º
                if current_dim != embedding_dim and current_dim != -1:
                    logger.warning(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç–∞–±–ª–∏—Ü—ã ({current_dim}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç—Ä–µ–±—É–µ–º–æ–π ({embedding_dim}). –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É.")
                    await cls._recreate_table(conn, embedding_dim)
                else:
                    logger.info(f"–¢–∞–±–ª–∏—Ü–∞ documents —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é: {embedding_dim}")
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
                await cls._create_table(conn, embedding_dim)

    @classmethod
    async def _create_table(cls, conn, embedding_dim):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        await conn.execute(f'''
            CREATE TABLE IF NOT EXISTS documents (
                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                content TEXT NOT NULL,
                embedding VECTOR({embedding_dim}),
                metadata JSONB DEFAULT '{{}}',
                created_at TIMESTAMPTZ DEFAULT NOW(),
                updated_at TIMESTAMPTZ DEFAULT NOW()
            );
        ''')
        
        # Create index for vector search (–∏—Å–ø–æ–ª—å–∑—É–µ–º HNSW –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        await conn.execute(f'''
            CREATE INDEX IF NOT EXISTS documents_embedding_hnsw_idx 
            ON documents USING hnsw (embedding vector_cosine_ops);
        ''')
        
        # Create metadata index
        await conn.execute('''
            CREATE INDEX IF NOT EXISTS documents_metadata_idx 
            ON documents USING gin (metadata);
        ''')
        
        logger.info(f"–¢–∞–±–ª–∏—Ü–∞ documents —Å–æ–∑–¥–∞–Ω–∞ —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–æ–≤: {embedding_dim}")

    @classmethod
    async def _recreate_table(cls, conn, embedding_dim):
        """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –Ω–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é"""
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        await conn.execute('DROP INDEX IF EXISTS documents_embedding_hnsw_idx;')
        await conn.execute('DROP INDEX IF EXISTS documents_metadata_idx;')
        
        # –£–¥–∞–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É
        await conn.execute('DROP TABLE IF EXISTS documents;')
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–Ω–æ–≤–æ
        await cls._create_table(conn, embedding_dim)
        
        logger.info(f"–¢–∞–±–ª–∏—Ü–∞ documents –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ —Å –Ω–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é: {embedding_dim}")

    @classmethod
    async def recreate_documents_table(cls):
        """–ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã"""
        pool = await cls.get_pool()
        async with pool.acquire() as conn:
            embedding_dim = embedding_service.embedding_dim
            await cls._recreate_table(conn, embedding_dim)

    @classmethod
    async def close_pool(cls):
        if cls._pool and not cls._pool._closed:
            await cls._pool.close()
            cls._pool = None
            cls._initialized = False
            logger.info("Database connection pool closed")

    @classmethod
    def is_initialized(cls):
        return cls._initialized and cls._pool is not None and not cls._pool._closed

# Utility functions
async def get_database_pool():
    return await DatabaseManager.get_pool()

async def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    await DatabaseManager.get_pool()

async def close_database():
    """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    await DatabaseManager.close_pool()

async def recreate_documents_table():
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    await DatabaseManager.recreate_documents_table()

def is_database_initialized():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    return DatabaseManager.is_initialized()

delete

import asyncio
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.database import recreate_documents_table
from app.services.vector_store import vector_store

async def main():
    try:
        print("–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã documents...")
        await recreate_documents_table()
        print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞!")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º vector_store –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        await vector_store.init()
        info = await vector_store.get_collection_info()
        print(f"üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ë–î: {info}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        from app.core.database import close_database
        await close_database()

if __name__ == "__main__":
    asyncio.run(main())

