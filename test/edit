@classmethod
async def _create_table(cls, conn, embedding_dim):
    """Создание таблицы документов с оптимизированными индексами"""
    await conn.execute(f'''
        CREATE TABLE IF NOT EXISTS documents (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            content TEXT NOT NULL,
            embedding VECTOR({embedding_dim}),
            metadata JSONB DEFAULT '{{}}',
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        );
    ''')
    
    # Оптимизированный HNSW индекс с лучшими параметрами
    await conn.execute(f'''
        CREATE INDEX IF NOT EXISTS documents_embedding_hnsw_idx 
        ON documents USING hnsw (embedding vector_cosine_ops)
        WITH (m = 16, ef_construction = 64);
    ''')
    
    # Дополнительный индекс для полнотекстового поиска
    await conn.execute('''
        CREATE INDEX IF NOT EXISTS documents_content_gin_idx 
        ON documents USING gin (to_tsvector('russian', content));
    ''')
    
    # Индекс для метаданных
    await conn.execute('''
        CREATE INDEX IF NOT EXISTS documents_metadata_idx 
        ON documents USING gin (metadata);
    ''')
    
    logger.info(f"Таблица documents создана с оптимизированными индексами")


database

vector

async def search(self, query: str, top_k: Optional[int] = None, min_score: float = 0.3) -> List[Dict[str, Any]]:
    """Улучшенный поиск с гибридным подходом"""
    if top_k is None:
        top_k = settings.TOP_K

    await self.ensure_connection()

    try:
        # Создаем эмбеддинг для запроса
        logger.info(f"Создание эмбеддинга для запроса: {query[:100]}...")
        query_embedding = embedding_service.encode(query)
        prepared_embedding = self._prepare_embedding(query_embedding)

        async with self.pool.acquire() as conn:
            # Устанавливаем параметры поиска для лучшей точности
            await conn.execute("SET hnsw.ef_search = 100;")  # Увеличиваем точность поиска HNSW
            
            # Комбинированный поиск: векторный + полнотекстовый
            results = await conn.fetch('''
                WITH vector_search AS (
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> $1::vector) as similarity
                    FROM documents
                    WHERE embedding <=> $1::vector < 0.8  -- Фильтр по порогу расстояния
                    ORDER BY embedding <=> $1::vector
                    LIMIT $2 * 2  # Берем в 2 раза больше для последующей фильтрации
                ),
                text_search AS (
                    SELECT 
                        id,
                        content,
                        metadata,
                        ts_rank(to_tsvector('russian', content), plainto_tsquery('russian', $3)) as ts_rank
                    FROM documents
                    WHERE to_tsvector('russian', content) @@ plainto_tsquery('russian', $3)
                    ORDER BY ts_rank DESC
                    LIMIT $2
                )
                -- Объединяем результаты с весами
                SELECT 
                    vs.id,
                    vs.content,
                    vs.metadata,
                    vs.similarity as vector_score,
                    COALESCE(ts.ts_rank, 0) as text_score,
                    (vs.similarity * 0.7 + COALESCE(ts.ts_rank, 0) * 0.3) as combined_score
                FROM vector_search vs
                LEFT JOIN text_search ts ON vs.id = ts.id
                WHERE vs.similarity > $4  # Порог по векторному сходству
                ORDER BY combined_score DESC
                LIMIT $2
            ''', prepared_embedding, top_k, query, min_score)

            formatted_results = []
            for row in results:
                formatted_results.append({
                    "id": str(row["id"]),
                    "document": row["content"],
                    "metadata": row["metadata"] or {},
                    "distance": 1 - float(row["vector_score"]),
                    "score": float(row["combined_score"]),
                    "vector_score": float(row["vector_score"]),
                    "text_score": float(row["text_score"])
                })

            logger.info(f"Найдено {len(formatted_results)} релевантных документов (улучшенный поиск)")
            return formatted_results

    except Exception as e:
        logger.error(f"Ошибка улучшенного поиска: {e}")
        # Fallback к простому векторному поиску
        return await self._fallback_search(query, top_k, prepared_embedding)

async def _fallback_search(self, query: str, top_k: int, prepared_embedding: str) -> List[Dict[str, Any]]:
    """Резервный поиск только по векторам"""
    try:
        async with self.pool.acquire() as conn:
            await conn.execute("SET hnsw.ef_search = 80;")
            
            results = await conn.fetch('''
                SELECT 
                    id,
                    content,
                    metadata,
                    1 - (embedding <=> $1::vector) as similarity
                FROM documents
                ORDER BY embedding <=> $1::vector
                LIMIT $2
            ''', prepared_embedding, top_k)

            formatted_results = []
            for row in results:
                formatted_results.append({
                    "id": str(row["id"]),
                    "document": row["content"],
                    "metadata": row["metadata"] or {},
                    "distance": 1 - float(row["similarity"]),
                    "score": float(row["similarity"])
                })

            return formatted_results
    except Exception as e:
        logger.error(f"Ошибка резервного поиска: {e}")
        return []

config

import os
from typing import Optional
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... существующие настройки ...
    
    # Новые настройки для улучшения поиска
    SEARCH_EF_SEARCH: int = 100  # Параметр точности HNSW поиска
    SEARCH_MIN_SCORE: float = 0.3  # Минимальный порог релевантности
    SEARCH_HYBRID_WEIGHT_VECTOR: float = 0.7  # Вес векторного поиска
    SEARCH_HYBRID_WEIGHT_TEXT: float = 0.3  # Вес полнотекстового поиска
    
    class Config:
        env_file = ".env"

settings = Settings()

Создайте скрипт для настройки PostgreSQL scripts/optimize_db.py:

python
import asyncio
import asyncpg
from app.config import settings
from loguru import logger

async def optimize_postgresql():
    """Оптимизация PostgreSQL для векторного поиска"""
    try:
        conn = await asyncpg.connect(settings.DATABASE_URL)
        
        # Оптимизация параметров PostgreSQL для векторного поиска
        optimizations = [
            "SET shared_preload_libraries = 'vector';",
            "SET work_mem = '256MB';",
            "SET maintenance_work_mem = '512MB';",
            "SET effective_cache_size = '2GB';",
            "SET random_page_cost = 1.1;",
            "SET effective_io_concurrency = 200;"
        ]
        
        for optimization in optimizations:
            try:
                await conn.execute(optimization)
                logger.info(f"Применена оптимизация: {optimization}")
            except Exception as e:
                logger.warning(f"Не удалось применить {optimization}: {e}")
        
        await conn.close()
        logger.success("Оптимизация PostgreSQL завершена")
        
    except Exception as e:
        logger.error(f"Ошибка оптимизации PostgreSQL: {e}")

if __name__ == "__main__":
    asyncio.run(optimize_postgresql())

def encode(self, texts):
    # ... существующий код ...
    
    # Создаем эмбеддинги с нормализацией
    embeddings = self.model.encode(
        texts, 
        convert_to_tensor=False, 
        normalize_embeddings=True,  # Важно для косинусного расстояния
        show_progress_bar=False
    )
    
    # Дополнительная нормализация для безопасности
    if isinstance(embeddings, np.ndarray):
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        embeddings = embeddings / np.where(norms == 0, 1, norms)
    
    # ... остальной код ...

import asyncio
import numpy as np
from app.core.database import get_database_pool
from app.services.embedding import embedding_service

async def check_embedding_quality():
    """Проверка качества эмбеддингов в базе данных"""
    pool = await get_database_pool()
    
    async with pool.acquire() as conn:
        # Проверяем среднюю длину векторов
        result = await conn.fetchval('''
            SELECT AVG(array_length(embedding::text::float8[], 1)) 
            FROM documents 
            LIMIT 100
        ''')
        print(f"Средняя размерность векторов: {result}")
        
        # Проверяем нормализацию
        result = await conn.fetch('''
            SELECT 
                id,
                sqrt(sum(unnest::double precision * unnest::double precision)) as norm
            FROM (
                SELECT id, unnest(string_to_array(trim(embedding::text, '[]'), ','))::float8 as unnest
                FROM documents 
                LIMIT 50
            ) t
            GROUP BY id
        ''')
        
        norms = [row['norm'] for row in result]
        print(f"Средняя норма векторов: {np.mean(norms):.4f} (+/- {np.std(norms):.4f})")
        
        # Проверка на NaN значения
        nan_check = await conn.fetchval('''
            SELECT COUNT(*) 
            FROM documents 
            WHERE embedding::text LIKE '%NaN%' OR embedding::text LIKE '%Inf%'
        ''')
        print(f"Найдено некорректных векторов: {nan_check}")

if __name__ == "__main__":
    asyncio.run(check_embedding_quality())
