bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è rag_user
sudo -u postgres psql -c "ALTER USER rag_user WITH PASSWORD 'secure_password';"

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å –ø–∞—Ä–æ–ª–µ–º
psql -h localhost -U rag_user -d rag_db -W
requirements.txt:
txt
# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º
psycopg2-binary==2.9.7
sqlalchemy==2.0.23
alembic==1.12.1
–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö:

bash
pip install psycopg2-binary sqlalchemy alembic
app/main.py
python
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

from app.config import settings
from app.core.database import init_database, close_database
from app.services.vector_store import vector_store
from app.services.vllm_manager import vllm_manager, cleanup_all_vllm_processes

# Import routers
from app.routers import health, chat, files

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await init_database()
    await vector_store.init()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º vLLM —Å–µ—Ä–≤–µ—Ä
    print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è vLLM —Å–µ—Ä–≤–µ—Ä–∞...")
    if not vllm_manager.start_vllm_server():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å vLLM —Å–µ—Ä–≤–µ—Ä. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
        raise RuntimeError("VLLM server failed to start")
    
    yield
    
    # Shutdown
    vllm_manager.stop_vllm_server()
    cleanup_all_vllm_processes()
    await close_database()

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è FastAPI
app = FastAPI(
    title="RAG System with vLLM",
    description="–°–∏—Å—Ç–µ–º–∞ RAG —Å vLLM –∏ PostgreSQL –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# Include routers
app.include_router(health.router, prefix="/api/v1", tags=["health"])
app.include_router(chat.router, prefix="/api/v1", tags=["chat"])
app.include_router(files.router, prefix="/api/v1", tags=["files"])

@app.get("/")
async def root():
    return {"message": "RAG System with vLLM and PostgreSQL", "status": "running"}

@app.get("/api/v1")
async def api_info():
    return {
        "name": "RAG API",
        "version": "1.0.0",
        "models": {
            "llm": settings.VLLM_MODEL_NAME,
            "embedding": settings.EMBEDDING_MODEL,
            "reranker": settings.RERANKER_MODEL
        }
    }
start_server.py (–∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞)
python
import os
import sys
import uvicorn
from app.config import settings
from app.utils.logger import setup_logger

def setup_environment():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    os.makedirs("uploads", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    os.makedirs("static", exist_ok=True)

def print_startup_info():
    """–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—É—Å–∫–µ"""
    print("\n" + "="*60)
    print("üöÄ –ó–∞–ø—É—Å–∫ RAG —Å–∏—Å—Ç–µ–º—ã —Å vLLM –∏ PostgreSQL")
    print("="*60)
    print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"   - –°–µ—Ä–≤–µ—Ä: http://{settings.HOST}:{settings.PORT}")
    print(f"   - API: http://{settings.HOST}:{settings.PORT}/api/v1")
    print(f"   - vLLM: {settings.VLLM_BASE_URL}")
    print(f"   - –ú–æ–¥–µ–ª—å: {settings.VLLM_MODEL_NAME}")
    print(f"   - –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: PostgreSQL —Å pgvector")
    print(f"   - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://{settings.HOST}:{settings.PORT}/docs")
    print()
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ endpoints:")
    print("   GET  /                   - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ API")
    print("   POST /api/v1/upload      - –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
    print("   POST /api/v1/chat        - –ß–∞—Ç —Å RAG")
    print("   GET  /api/v1/health      - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    print("="*60)
    print()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
    setup_environment()
    setup_logger()
    
    print_startup_info()

    try:
        uvicorn.run(
            "app.main:app",
            host=settings.HOST,
            port=settings.PORT,
            reload=True,
            log_level="info",
            access_log=True,
        )
    except KeyboardInterrupt:
        print("\nüõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è...")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        print("üëã –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    main()
üóÑÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/core/database.py
python
import asyncpg
from app.config import settings
from loguru import logger

class DatabaseManager:
    _pool = None

    @classmethod
    async def get_pool(cls):
        if cls._pool is None:
            try:
                cls._pool = await asyncpg.create_pool(
                    settings.DATABASE_URL,
                    min_size=5,
                    max_size=20,
                    command_timeout=60
                )
                logger.info("PostgreSQL connection pool created successfully")
                
                # Initialize database schema
                await cls._init_schema()
                
            except Exception as e:
                logger.error(f"Failed to create database connection pool: {e}")
                raise
        return cls._pool

    @classmethod
    async def _init_schema(cls):
        """Initialize database tables and indexes"""
        pool = await cls.get_pool()
        async with pool.acquire() as conn:
            # Enable vector extension
            await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            
            # Create documents table
            await conn.execute('''
                CREATE TABLE IF NOT EXISTS documents (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    content TEXT NOT NULL,
                    embedding VECTOR(384),
                    metadata JSONB DEFAULT '{}',
                    created_at TIMESTAMPTZ DEFAULT NOW(),
                    updated_at TIMESTAMPTZ DEFAULT NOW()
                );
            ''')
            
            # Create index for vector search
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS documents_embedding_idx 
                ON documents USING ivfflat (embedding vector_cosine_ops)
                WITH (lists = 100);
            ''')
            
            # Create metadata index
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS documents_metadata_idx 
                ON documents USING gin (metadata);
            ''')
            
            logger.info("Database schema initialized successfully")

    @classmethod
    async def close_pool(cls):
        if cls._pool:
            await cls._pool.close()
            cls._pool = None
            logger.info("Database connection pool closed")

# Utility functions
async def get_database_pool():
    return await DatabaseManager.get_pool()

async def init_database():
    await DatabaseManager.get_pool()

async def close_database():
    await DatabaseManager.close_pool()
üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/services/vector_store.py (pgvector)
python
import uuid
from typing import Any, Dict, List, Optional
import numpy as np

from app.config import settings
from app.core.database import get_database_pool
from app.services.embedding import embedding_service
from loguru import logger

class PGVectorStoreService:
    def __init__(self):
        self.embedding_dim = 384  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è multilingual-MiniLM-L12-v2
        self.pool = None

    async def init(self):
        """Initialize connection pool"""
        self.pool = await get_database_pool()

    async def add_documents(
        self, documents: List[str], metadatas: List[Dict[str, Any]] = None
    ) -> List[str]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ PostgreSQL"""
        if not documents:
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return []

        if metadatas is None:
            metadatas = [{}] * len(documents)
        elif len(metadatas) != len(documents):
            logger.warning("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            metadatas = [{}] * len(documents)

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            embeddings = embedding_service.encode(documents)

            ids = []
            async with self.pool.acquire() as conn:
                for i, (doc, embedding, metadata) in enumerate(zip(documents, embeddings, metadatas)):
                    doc_id = str(uuid.uuid4())
                    # Convert embedding to list for PostgreSQL
                    embedding_list = embedding.tolist() if hasattr(embedding, 'tolist') else embedding
                    
                    await conn.execute('''
                        INSERT INTO documents (id, content, embedding, metadata)
                        VALUES ($1, $2, $3, $4)
                    ''', doc_id, doc, embedding_list, metadata)
                    
                    ids.append(doc_id)

            logger.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL")
            return ids

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL: {e}")
            raise

    async def search(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PostgreSQL"""
        if top_k is None:
            top_k = settings.TOP_K

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = embedding_service.encode(query)
            query_embedding_list = query_embedding.tolist() if hasattr(query_embedding, 'tolist') else query_embedding

            async with self.pool.acquire() as conn:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                results = await conn.fetch('''
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> $1) as similarity
                    FROM documents
                    ORDER BY embedding <=> $1
                    LIMIT $2
                ''', query_embedning_list, top_k)

                formatted_results = []
                for row in results:
                    formatted_results.append({
                        "id": str(row["id"]),
                        "document": row["content"],
                        "metadata": row["metadata"] or {},
                        "distance": 1 - float(row["similarity"]),
                        "score": float(row["similarity"])
                    })

                logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(formatted_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                return formatted_results

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ PostgreSQL: {e}")
            return []

    async def get_collection_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            async with self.pool.acquire() as conn:
                count = await conn.fetchval("SELECT COUNT(*) FROM documents")
                return {
                    "database": "PostgreSQL",
                    "table_name": "documents",
                    "document_count": count,
                    "status": "healthy",
                    "vector_dimension": self.embedding_dim
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return {
                "database": "PostgreSQL",
                "table_name": "documents",
                "document_count": 0,
                "status": "error",
                "error": str(e)
            }

    async def delete_all_documents(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("DELETE FROM documents")
                logger.info("–í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —É–¥–∞–ª–µ–Ω—ã –∏–∑ PostgreSQL")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            raise

# Global instance
vector_store = PGVectorStoreService()
üí¨ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π app/routers/chat.py
python
from typing import List, Optional
from app.config import settings
from app.services.llm_service import llm_service
from app.services.reranker import reranker_service
from app.services.vector_store import vector_store
from fastapi import APIRouter, HTTPException
from loguru import logger
from pydantic import BaseModel, Field

router = APIRouter()

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤
conversation_store = {}

class ChatRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    use_reranking: bool = True

class ChatResponse(BaseModel):
    response: str = Field(default="")
    conversation_id: str = Field(default="default")
    sources: List[str] = Field(default_factory=list)
    suggested_questions: List[str] = Field(default_factory=list)

@router.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —á–∞—Ç–∞: {request.message}")

        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º ID –¥–∏–∞–ª–æ–≥–∞
        conversation_id = request.conversation_id or f"conv_{len(conversation_store) + 1}"

        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        history = conversation_store.get(conversation_id, [])

        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        search_results = await vector_store.search(request.message, top_k=settings.TOP_K)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(search_results)}")

        response_text = ""
        sources = []

        if not search_results:
            response_text = (
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å."
            )
            logger.info("–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç")
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            documents = [result["document"] for result in search_results]
            logger.info(f"–ü–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {documents[0][:100]}..." if documents else "–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            # –†–µ—Ä–∞–Ω–∫–∏–Ω–≥ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
            if request.use_reranking and len(documents) > 1:
                logger.info("–ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                reranked_docs = reranker_service.rerank(
                    request.message, documents, top_k=settings.RERANK_TOP_K
                )
                context_docs = [doc for doc, score in reranked_docs]
            else:
                context_docs = documents[: settings.RERANK_TOP_K]

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º...")
            response_text = llm_service.generate_with_context(
                question=request.message,
                context=context_docs,
                conversation_history=history,
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not response_text or response_text.strip() == "":
                response_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

            sources = [result["document"][:100] + "..." for result in search_results[:3]]

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        history.extend([
            {"role": "user", "content": request.message},
            {"role": "assistant", "content": response_text},
        ])

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 10 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        conversation_store[conversation_id] = history[-10:]

        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        suggested_questions = [
            "–ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å?",
            "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∏—Å–∫?",
            "–ö–∞–∫–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è?",
        ]

        logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤")

        return ChatResponse(
            response=response_text,
            conversation_id=conversation_id,
            sources=sources,
            suggested_questions=suggested_questions,
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —á–∞—Ç–µ: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")

@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞"""
    history = conversation_store.get(conversation_id, [])
    return {"conversation_id": conversation_id, "history": history}

