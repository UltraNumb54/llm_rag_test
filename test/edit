import asyncpg
from app.config import settings
from loguru import logger

class DatabaseManager:
    _pool = None

    @classmethod
    async def get_pool(cls):
        if cls._pool is None:
            try:
                cls._pool = await asyncpg.create_pool(
                    settings.DATABASE_URL,
                    min_size=5,
                    max_size=20,
                    command_timeout=60
                )
                logger.info("PostgreSQL connection pool created successfully")
                
                # Initialize database schema
                await cls._init_schema()
                
            except Exception as e:
                logger.error(f"Failed to create database connection pool: {e}")
                raise
        return cls._pool

    @classmethod
    async def _init_schema(cls):
        """Initialize database tables and indexes"""
        pool = await cls.get_pool()
        async with pool.acquire() as conn:
            # Enable vector extension
            await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            
            # Create documents table
            await conn.execute('''
                CREATE TABLE IF NOT EXISTS documents (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    content TEXT NOT NULL,
                    embedding VECTOR(384),
                    metadata JSONB DEFAULT '{}',
                    created_at TIMESTAMPTZ DEFAULT NOW(),
                    updated_at TIMESTAMPTZ DEFAULT NOW()
                );
            ''')
            
            # Create index for vector search
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS documents_embedding_idx 
                ON documents USING ivfflat (embedding vector_cosine_ops)
                WITH (lists = 100);
            ''')
            
            # Create metadata index
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS documents_metadata_idx 
                ON documents USING gin (metadata);
            ''')
            
            logger.info("Database schema initialized successfully")

    @classmethod
    async def close_pool(cls):
        if cls._pool:
            await cls._pool.close()
            cls._pool = None
            logger.info("Database connection pool closed")

# Utility functions
async def get_database_pool():
    return await DatabaseManager.get_pool()

async def init_database():
    """Инициализация базы данных - должна быть завершена ДО запуска приложения"""
    await DatabaseManager.get_pool()

async def close_database():
    """Закрытие соединений с базой данных"""
    await DatabaseManager.close_pool()


import uuid
from typing import Any, Dict, List, Optional
import numpy as np

from app.config import settings
from app.core.database import get_database_pool
from app.services.embedding import embedding_service
from loguru import logger

class PGVectorStoreService:
    def __init__(self):
        self.embedding_dim = 384  # Размерность для multilingual-MiniLM-L12-v2
        self.pool = None

    async def init(self):
        """Initialize connection pool - должна быть завершена ДО использования"""
        if self.pool is None:
            self.pool = await get_database_pool()
            logger.info("Vector store service initialized")

    async def add_documents(
        self, documents: List[str], metadatas: List[Dict[str, Any]] = None
    ) -> List[str]:
        """Добавление документов в векторное хранилище PostgreSQL"""
        if not documents:
            logger.warning("Попытка добавить пустой список документов")
            return []

        if metadatas is None:
            metadatas = [{}] * len(documents)
        elif len(metadatas) != len(documents):
            logger.warning("Количество метаданных не совпадает с количеством документов")
            metadatas = [{}] * len(documents)

        try:
            # Создаем эмбеддинги
            logger.info(f"Создание эмбеддингов для {len(documents)} документов...")
            embeddings = embedding_service.encode(documents)

            ids = []
            async with self.pool.acquire() as conn:
                for i, (doc, embedding, metadata) in enumerate(zip(documents, embeddings, metadatas)):
                    doc_id = str(uuid.uuid4())
                    # Convert embedding to list for PostgreSQL
                    embedding_list = embedding.tolist() if hasattr(embedding, 'tolist') else embedding
                    
                    await conn.execute('''
                        INSERT INTO documents (id, content, embedding, metadata)
                        VALUES ($1, $2, $3, $4)
                    ''', doc_id, doc, embedding_list, metadata)
                    
                    ids.append(doc_id)

            logger.success(f"Добавлено {len(documents)} документов в PostgreSQL")
            return ids

        except Exception as e:
            logger.error(f"Ошибка добавления документов в PostgreSQL: {e}")
            raise

    async def search(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """Поиск похожих документов в PostgreSQL"""
        if top_k is None:
            top_k = settings.TOP_K

        try:
            # Создаем эмбеддинг для запроса
            query_embedding = embedding_service.encode(query)
            query_embedding_list = query_embedding.tolist() if hasattr(query_embedding, 'tolist') else query_embedding

            async with self.pool.acquire() as conn:
                # Используем косинусное расстояние
                results = await conn.fetch('''
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> $1) as similarity
                    FROM documents
                    ORDER BY embedding <=> $1
                    LIMIT $2
                ''', query_embedding_list, top_k)

                formatted_results = []
                for row in results:
                    formatted_results.append({
                        "id": str(row["id"]),
                        "document": row["content"],
                        "metadata": row["metadata"] or {},
                        "distance": 1 - float(row["similarity"]),
                        "score": float(row["similarity"])
                    })

                logger.debug(f"Найдено {len(formatted_results)} релевантных документов")
                return formatted_results

        except Exception as e:
            logger.error(f"Ошибка поиска в PostgreSQL: {e}")
            return []

    async def get_collection_info(self) -> Dict[str, Any]:
        """Получение информации о коллекции документов"""
        try:
            async with self.pool.acquire() as conn:
                count = await conn.fetchval("SELECT COUNT(*) FROM documents")
                return {
                    "database": "PostgreSQL",
                    "table_name": "documents",
                    "document_count": count,
                    "status": "healthy",
                    "vector_dimension": self.embedding_dim
                }
        except Exception as e:
            logger.error(f"Ошибка получения информации о коллекции: {e}")
            return {
                "database": "PostgreSQL",
                "table_name": "documents",
                "document_count": 0,
                "status": "error",
                "error": str(e)
            }

    async def delete_all_documents(self):
        """Удаление всех документов (для тестирования)"""
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("DELETE FROM documents")
                logger.info("Все документы удалены из PostgreSQL")
        except Exception as e:
            logger.error(f"Ошибка удаления документов: {e}")
            raise

# Global instance
vector_store = PGVectorStoreService()

