embedd

import numpy as np
from sentence_transformers import SentenceTransformer
from app.config import settings
from loguru import logger

class EmbeddingService:
    def __init__(self):
        self.model_name = settings.EMBEDDING_MODEL
        self.model = None
        self.embedding_dim = 384
        self._load_model()

    def _load_model(self):
        """Загрузка модели эмбеддингов с обработкой ошибок"""
        try:
            logger.info(f"Загрузка модели эмбеддингов: {self.model_name}")
            
            # Пробуем загрузить модель с разными параметрами
            self.model = SentenceTransformer(
                self.model_name,
                device='cpu',  # Явно указываем CPU
                trust_remote_code=True
            )
            
            # Тестируем модель
            test_texts = ["тестовый текст для проверки эмбеддингов"]
            test_embeddings = self.model.encode(test_texts)
            
            # Проверяем размерность
            if hasattr(test_embeddings, 'shape'):
                actual_dim = test_embeddings.shape[1] if len(test_embeddings.shape) > 1 else test_embeddings.shape[0]
            else:
                actual_dim = len(test_embeddings[0]) if hasattr(test_embeddings[0], '__len__') else 1
                
            logger.info(f"Модель загружена. Размерность эмбеддингов: {actual_dim}")
            
            if actual_dim != self.embedding_dim:
                logger.warning(f"Фактическая размерность ({actual_dim}) не совпадает с ожидаемой ({self.embedding_dim})")
                self.embedding_dim = actual_dim
                
        except Exception as e:
            logger.error(f"Ошибка загрузки модели {self.model_name}: {e}")
            logger.info("Пробуем загрузить альтернативную модель...")
            self._load_fallback_model()

    def _load_fallback_model(self):
        """Загрузка резервной модели"""
        fallback_models = [
            "sentence-transformers/all-MiniLM-L6-v2",  # 384 размерность
            "sentence-transformers/paraphrase-albert-small-v2",  # 768 размерность
            "sentence-transformers/all-distilroberta-v1"  # 768 размерность
        ]
        
        for fallback_model in fallback_models:
            try:
                logger.info(f"Пробуем загрузить резервную модель: {fallback_model}")
                self.model = SentenceTransformer(fallback_model, device='cpu')
                self.model_name = fallback_model
                
                # Тестируем
                test_embeddings = self.model.encode(["тестовый текст"])
                if hasattr(test_embeddings, 'shape'):
                    self.embedding_dim = test_embeddings.shape[1] if len(test_embeddings.shape) > 1 else test_embeddings.shape[0]
                else:
                    self.embedding_dim = len(test_embeddings[0]) if hasattr(test_embeddings[0], '__len__') else 384
                    
                logger.success(f"Резервная модель загружена: {fallback_model}, размерность: {self.embedding_dim}")
                return
                
            except Exception as e:
                logger.error(f"Ошибка загрузки резервной модели {fallback_model}: {e}")
                continue
        
        # Если все модели не загрузились, создаем фиктивные эмбеддинги
        logger.error("Не удалось загрузить ни одну модель эмбеддингов. Используем фиктивные эмбеддинги.")
        self.model = None
        self.embedding_dim = 384

    def encode(self, texts):
        """Создание эмбеддингов для текстов"""
        if not texts:
            return np.array([])
            
        try:
            # Если модель не загружена, создаем фиктивные эмбеддинги
            if self.model is None:
                if isinstance(texts, str):
                    texts = [texts]
                # Создаем случайные эмбеддинги правильной размерности
                embeddings = np.random.randn(len(texts), self.embedding_dim).astype(np.float32)
                logger.warning("Используются фиктивные эмбеддинги")
                return embeddings
                
            # Если передан один текст, преобразуем в список
            if isinstance(texts, str):
                texts = [texts]
                
            # Создаем эмбеддинги
            embeddings = self.model.encode(texts, convert_to_tensor=False, normalize_embeddings=True)
            
            # Преобразуем в numpy array если нужно
            if not isinstance(embeddings, np.ndarray):
                embeddings = np.array(embeddings)
                
            # Обеспечиваем правильную размерность
            if embeddings.ndim == 1:
                embeddings = embeddings.reshape(1, -1)
                
            # Логируем информацию о эмбеддингах
            logger.debug(f"Созданы эмбеддинги: форма={embeddings.shape}, тип={type(embeddings)}")
            
            return embeddings
            
        except Exception as e:
            logger.error(f"Ошибка создания эмбеддингов: {e}")
            # Возвращаем фиктивные эмбеддинги при ошибке
            if isinstance(texts, str):
                texts = [texts]
            return np.random.randn(len(texts), self.embedding_dim).astype(np.float32)

# Глобальный экземпляр сервиса
embedding_service = EmbeddingService()

database

import asyncpg
from app.config import settings
from app.services.embedding import embedding_service
from loguru import logger

class DatabaseManager:
    _pool = None
    _initialized = False

    @classmethod
    async def get_pool(cls):
        if cls._pool is None or cls._pool._closed:
            try:
                cls._pool = await asyncpg.create_pool(
                    settings.DATABASE_URL,
                    min_size=5,
                    max_size=20,
                    command_timeout=60,
                    max_inactive_connection_lifetime=300
                )
                cls._initialized = True
                logger.info("PostgreSQL connection pool created successfully")
                
                # Initialize database schema
                await cls._init_schema()
                
            except Exception as e:
                logger.error(f"Failed to create database connection pool: {e}")
                raise
        return cls._pool

    @classmethod
    async def _init_schema(cls):
        """Initialize database tables and indexes"""
        pool = await cls.get_pool()
        async with pool.acquire() as conn:
            # Enable vector extension
            await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            
            # Получаем актуальную размерность из сервиса эмбеддингов
            embedding_dim = embedding_service.embedding_dim
            
            # Проверяем существование таблицы и её структуру
            table_exists = await conn.fetchval("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = 'documents'
                );
            """)
            
            if table_exists:
                # Проверяем размерность существующей таблицы
                current_dim = await conn.fetchval("""
                    SELECT COUNT(*) FROM information_schema.columns 
                    WHERE table_name = 'documents' 
                    AND column_name = 'embedding'
                    AND data_type = 'USER-DEFINED'
                """)
                
                if current_dim == 0:
                    # Пересоздаем таблицу с правильной размерностью
                    await conn.execute("DROP TABLE IF EXISTS documents;")
                    await cls._create_table(conn, embedding_dim)
                else:
                    logger.info(f"Таблица documents уже существует с размерностью векторов: {embedding_dim}")
            else:
                # Создаем новую таблицу
                await cls._create_table(conn, embedding_dim)

    @classmethod
    async def _create_table(cls, conn, embedding_dim):
        """Создание таблицы документов"""
        await conn.execute(f'''
            CREATE TABLE documents (
                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                content TEXT NOT NULL,
                embedding VECTOR({embedding_dim}),
                metadata JSONB DEFAULT '{{}}',
                created_at TIMESTAMPTZ DEFAULT NOW(),
                updated_at TIMESTAMPTZ DEFAULT NOW()
            );
        ''')
        
        # Create index for vector search
        await conn.execute(f'''
            CREATE INDEX documents_embedding_idx 
            ON documents USING ivfflat (embedding vector_cosine_ops)
            WITH (lists = 100);
        ''')
        
        # Create metadata index
        await conn.execute('''
            CREATE INDEX documents_metadata_idx 
            ON documents USING gin (metadata);
        ''')
        
        logger.info(f"Таблица documents создана с размерностью векторов: {embedding_dim}")

    @classmethod
    async def close_pool(cls):
        if cls._pool and not cls._pool._closed:
            await cls._pool.close()
            cls._pool = None
            cls._initialized = False
            logger.info("Database connection pool closed")

    @classmethod
    def is_initialized(cls):
        return cls._initialized and cls._pool is not None and not cls._pool._closed

# Utility functions
async def get_database_pool():
    return await DatabaseManager.get_pool()

async def init_database():
    """Инициализация базы данных"""
    await DatabaseManager.get_pool()

async def close_database():
    """Закрытие соединений с базой данных"""
    await DatabaseManager.close_pool()

def is_database_initialized():
    """Проверка инициализации базы данных"""
    return DatabaseManager.is_initialized()

vector

import uuid
import json
import math
from typing import Any, Dict, List, Optional
import numpy as np

from app.config import settings
from app.core.database import get_database_pool, is_database_initialized
from app.services.embedding import embedding_service
from loguru import logger

class PGVectorStoreService:
    def __init__(self):
        self.embedding_dim = embedding_service.embedding_dim
        self.pool = None
        self.initialized = False

    async def init(self):
        """Initialize connection pool"""
        try:
            if not is_database_initialized():
                logger.info("Инициализация пула соединений с базой данных...")
                self.pool = await get_database_pool()
                self.initialized = True
                logger.info(f"Vector store service initialized with embedding dim: {self.embedding_dim}")
            else:
                self.pool = await get_database_pool()
                self.initialized = True
        except Exception as e:
            logger.error(f"Ошибка инициализации vector store: {e}")
            raise

    async def ensure_connection(self):
        """Убедиться, что соединение активно"""
        if not self.initialized or self.pool is None or self.pool._closed:
            logger.warning("Пул соединений недоступен, переинициализация...")
            await self.init()

    def _prepare_embedding(self, embedding) -> List[float]:
        """Подготовка эмбеддинга для PostgreSQL"""
        # Если эмбеддинг - это numpy array, преобразуем в список
        if hasattr(embedding, 'tolist'):
            embedding_list = embedding.tolist()
        else:
            embedding_list = embedding

        # Если это скаляр, создаем вектор нужной размерности
        if isinstance(embedding_list, (int, float)):
            embedding_list = [float(embedding_list)] * self.embedding_dim
            logger.warning(f"Скалярный эмбеддинг расширен до вектора размерности {self.embedding_dim}")
        elif len(embedding_list) != self.embedding_dim:
            logger.warning(f"Размерность эмбеддинга ({len(embedding_list)}) не совпадает с ожидаемой ({self.embedding_dim})")
            # Приводим к нужной размерности
            if len(embedding_list) > self.embedding_dim:
                embedding_list = embedding_list[:self.embedding_dim]
            else:
                embedding_list.extend([0.0] * (self.embedding_dim - len(embedding_list)))

        # Очищаем от некорректных значений
        cleaned_embedding = []
        for x in embedding_list:
            if isinstance(x, (int, float)) and not (math.isnan(x) or math.isinf(x)):
                cleaned_embedding.append(float(x))
            else:
                cleaned_embedding.append(0.0)

        return cleaned_embedding

    def _metadata_to_jsonb(self, metadata: Dict[str, Any]) -> str:
        """Преобразование метаданных в JSON строку для PostgreSQL JSONB"""
        return json.dumps(metadata, ensure_ascii=False)

    async def add_documents(
        self, documents: List[str], metadatas: List[Dict[str, Any]] = None
    ) -> List[str]:
        """Добавление документов в векторное хранилище PostgreSQL"""
        if not documents:
            logger.warning("Попытка добавить пустой список документов")
            return []

        await self.ensure_connection()

        if metadatas is None:
            metadatas = [{}] * len(documents)
        elif len(metadatas) != len(documents):
            logger.warning("Количество метаданных не совпадает с количеством документов")
            metadatas = [{}] * len(documents)

        try:
            # Создаем эмбеддинги
            logger.info(f"Создание эмбеддингов для {len(documents)} документов...")
            embeddings = embedding_service.encode(documents)

            ids = []
            async with self.pool.acquire() as conn:
                for i, (doc, embedding, metadata) in enumerate(zip(documents, embeddings, metadatas)):
                    doc_id = str(uuid.uuid4())
                    # Подготавливаем эмбеддинг
                    prepared_embedding = self._prepare_embedding(embedding)
                    # Преобразуем метаданные в JSON строку
                    metadata_json = self._metadata_to_jsonb(metadata)
                    
                    await conn.execute('''
                        INSERT INTO documents (id, content, embedding, metadata)
                        VALUES ($1, $2, $3, $4::jsonb)
                    ''', doc_id, doc, prepared_embedding, metadata_json)
                    
                    ids.append(doc_id)

            logger.success(f"Добавлено {len(documents)} документов в PostgreSQL")
            return ids

        except Exception as e:
            logger.error(f"Ошибка добавления документов в PostgreSQL: {e}")
            raise

    async def search(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """Поиск похожих документов в PostgreSQL"""
        if top_k is None:
            top_k = settings.TOP_K

        await self.ensure_connection()

        try:
            # Создаем эмбеддинг для запроса
            logger.info(f"Создание эмбеддинга для запроса: {query[:100]}...")
            query_embedding = embedding_service.encode(query)
            prepared_embedding = self._prepare_embedding(query_embedding)

            logger.debug(f"Размерность эмбеддинга запроса: {len(prepared_embedding)}")

            async with self.pool.acquire() as conn:
                # Используем косинусное расстояние
                results = await conn.fetch('''
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> $1) as similarity
                    FROM documents
                    ORDER BY embedding <=> $1
                    LIMIT $2
                ''', prepared_embedding, top_k)

                formatted_results = []
                for row in results:
                    formatted_results.append({
                        "id": str(row["id"]),
                        "document": row["content"],
                        "metadata": row["metadata"] or {},
                        "distance": 1 - float(row["similarity"]),
                        "score": float(row["similarity"])
                    })

                logger.info(f"Найдено {len(formatted_results)} релевантных документов")
                return formatted_results

        except Exception as e:
            logger.error(f"Ошибка поиска в PostgreSQL: {e}")
            return []

    async def get_collection_info(self) -> Dict[str, Any]:
        """Получение информации о коллекции документов"""
        await self.ensure_connection()

        try:
            async with self.pool.acquire() as conn:
                count = await conn.fetchval("SELECT COUNT(*) FROM documents")
                return {
                    "database": "PostgreSQL",
                    "table_name": "documents",
                    "document_count": count,
                    "status": "healthy",
                    "vector_dimension": self.embedding_dim
                }
        except Exception as e:
            logger.error(f"Ошибка получения информации о коллекции: {e}")
            return {
                "database": "PostgreSQL",
                "table_name": "documents",
                "document_count": 0,
                "status": "error",
                "error": str(e)
            }

# Global instance
vector_store = PGVectorStoreService()
