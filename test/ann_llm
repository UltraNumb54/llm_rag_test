import csv
import time
import re
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000/v1")

def extract_clean_response(text):
    """Извлекает чистый ответ, убирая всё лишнее"""
    if text is None:
        return ""

    # Удаляем все теги форматирования и размышления
    clean_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    clean_text = re.sub(r'\*\*.*?\*\*', '', clean_text)  # Жирный текст
    clean_text = re.sub(r'\*.*?\*', '', clean_text)      # Курсив
    clean_text = re.sub(r'`.*?`', '', clean_text)        # Код
    clean_text = re.sub(r'#+', '', clean_text)           # Заголовки
    clean_text = re.sub(r'РАЗМЕЧЕННЫЙ ДИАЛОГ:?', '', clean_text, flags=re.IGNORECASE)
    clean_text = re.sub(r'РАЗМЕЧЕННЫЙ ТЕКСТ:?', '', clean_text, flags=re.IGNORECASE)
    clean_text = re.sub(r'АННОТИРОВАННЫЙ ТЕКСТ:?', '', clean_text, flags=re.IGNORECASE)

    # Убираем лишние пробелы и переносы
    clean_text = re.sub(r'\n+', ' ', clean_text)
    clean_text = re.sub(r'\s+', ' ', clean_text)

    return clean_text.strip()

def create_dialog_prompt(dialog_text):
    """Промпт для всего диалога"""
    return f'''
Замени персональные данные на метки [FIO], [LOC], [PHONE_NUM], [LK_NUM], [EMAIL] в этом диалоге:

{dialog_text}

Верни тот же диалог, но с заменёнными персональными данными на соответствующие метки.
Сохрани всю структуру диалога и все остальные слова без изменений.
Ответ (только размеченный диалог, без пояснений):
'''

def process_dialog_batch(dialog_batch):
    """Обрабатывает батч диалогов параллельно"""
    results = []
    
    for dialog_data in dialog_batch:
        dialog_id = dialog_data['id']
        dialog_messages = dialog_data['dialogue']
        
        # Собираем весь диалог в один текст
        dialog_text = "\n".join([f"{i+1}. {msg['text']}" for i, msg in enumerate(dialog_messages)])
        
        print(f"\n=== ЗАПРОС ДЛЯ ДИАЛОГА {dialog_id} ===")
        print(f"Промпт: {create_dialog_prompt(dialog_text)}")
        print("=" * 50)
        
        try:
            # Отправляем запрос для всего диалога
            response = client.chat.completions.create(
                model="Qwen3-8B-AWQ",
                messages=[{
                    "role": "user",
                    "content": create_dialog_prompt(dialog_text)
                }],
                temperature=0.1,
                max_tokens=4000  # Увеличиваем для длинных диалогов
            )

            result_text = response.choices[0].message.content
            
            print(f"\n=== ОТВЕТ ДЛЯ ДИАЛОГА {dialog_id} ===")
            print(f"Полный ответ: {result_text}")
            print("=" * 50)
            
            # Очищаем ответ
            clean_response = extract_clean_response(result_text)
            
            # Разбиваем ответ на отдельные сообщения
            annotated_messages = []
            lines = clean_response.split('\n')
            for line in lines:
                # Ищем строки с номерами сообщений
                match = re.match(r'^\d+\.\s*(.+)$', line.strip())
                if match:
                    annotated_messages.append(match.group(1))
            
            # Если не удалось разбить на сообщения, используем весь ответ для всех сообщений
            if len(annotated_messages) != len(dialog_messages):
                print(f"Предупреждение: количество размеченных сообщений ({len(annotated_messages)}) не совпадает с оригинальным ({len(dialog_messages)})")
                # Используем тот же размеченный текст для всех сообщений
                annotated_messages = [clean_response] * len(dialog_messages)
            
            # Сохраняем результаты для каждого сообщения
            for i, message in enumerate(dialog_messages):
                original_text = message['text']
                clean_original = re.sub(r'\n+', ' ', original_text)
                clean_original = re.sub(r'\s+', ' ', clean_original).strip()
                
                annotated_text = annotated_messages[i] if i < len(annotated_messages) else clean_response
                
                results.append({
                    'dialog_id': dialog_id,
                    'original_message': clean_original,
                    'annotated_message': annotated_text
                })
                
        except Exception as e:
            print(f"Ошибка в диалоге {dialog_id}: {str(e)}")
            # Сохраняем оригиналы с пометкой об ошибке
            for message in dialog_messages:
                original_text = message['text']
                clean_original = re.sub(r'\n+', ' ', original_text)
                clean_original = re.sub(r'\s+', ' ', clean_original).strip()
                
                results.append({
                    'dialog_id': dialog_id,
                    'original_message': clean_original,
                    'annotated_message': f"ОШИБКА: {str(e)}"
                })
    
    return results

def main():
    # Настройки
    input_file = "your_dataset.json"
    output_file = "annotated_dialogs.csv"
    max_dialogs = 2000
    batch_size = 8  # Количество параллельных запросов
    
    # Загрузка датасета
    with open(input_file, 'r', encoding='utf-8') as f:
        dataset = json.load(f)

    print(f"Загружено диалогов: {len(dataset)}")
    
    # Ограничиваем количество обрабатываемых диалогов
    dialogs_to_process = dataset[:max_dialogs]
    
    # Создаем CSV файл
    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['dialog_id', 'original_message', 'annotated_message']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)
        writer.writeheader()
        
        total_processed = 0
        success_count = 0
        
        # Разбиваем на батчи
        batches = [dialogs_to_process[i:i + batch_size] for i in range(0, len(dialogs_to_process), batch_size)]
        
        for batch_num, batch in enumerate(batches):
            print(f"\nОбработка батча {batch_num + 1}/{len(batches)} (размер: {len(batch)})")
            
            # Обрабатываем батч параллельно
            with ThreadPoolExecutor(max_workers=batch_size) as executor:
                # Запускаем обработку батча
                future = executor.submit(process_dialog_batch, batch)
                
                try:
                    batch_results = future.result(timeout=300)  # Таймаут 5 минут на батч
                    
                    # Записываем результаты
                    for result in batch_results:
                        writer.writerow(result)
                        success_count += 1
                    
                    total_processed += len(batch)
                    print(f"Батч {batch_num + 1} обработан успешно. Сообщений: {len(batch_results)}")
                    
                except Exception as e:
                    print(f"Ошибка при обработке батча {batch_num + 1}: {str(e)}")
                    # В случае ошибки батча, сохраняем оригиналы
                    for dialog in batch:
                        for message in dialog['dialogue']:
                            original_text = message['text']
                            clean_original = re.sub(r'\n+', ' ', original_text)
                            clean_original = re.sub(r'\s+', ' ', clean_original).strip()
                            
                            writer.writerow({
                                'dialog_id': dialog['id'],
                                'original_message': clean_original,
                                'annotated_message': f"ОШИБКА БАТЧА: {str(e)}"
                            })
            
            # Пауза между батчами чтобы не перегружать систему
            time.sleep(1)
    
    print(f"\n=== ИТОГ ===")
    print(f"Обработано диалогов: {total_processed}")
    print(f"Успешно размеченных сообщений: {success_count}")
    print(f"Файл сохранен: {output_file}")

if __name__ == "__main__":
    main()
