edit

import json
import time
import re
import os
from openai import OpenAI

client = OpenAI(api_key="EMPTY", base_url="http://localhost:8000/v1")

def extract_json_from_response(text):
    """Извлекает JSON из ответа модели, игнорируя размышления"""
    if text is None:
        return None
        
    # Упрощенный подход: ищем первый [ или { и пытаемся распарсить оттуда
    json_start_chars = ['[', '{']
    
    for start_char in json_start_chars:
        start_idx = text.find(start_char)
        if start_idx != -1:
            # Берем подстроку от начала JSON до конца
            json_str = text[start_idx:]
            
            # Пробуем распарсить, постепенно укорачивая строку если не получается
            for end_idx in range(len(json_str), 0, -1):
                try:
                    potential_json = json_str[:end_idx]
                    # Проверяем что это валидный JSON
                    result = json.loads(potential_json)
                    # Дополнительная проверка - должен быть список или словарь
                    if isinstance(result, (list, dict)):
                        return result
                except json.JSONDecodeError:
                    continue
    
    return None

def create_strict_prompt(dialogue_text):
    """Создает очень строгий промпт"""
    return f'''Верни ТОЛЬКО JSON без любых других текстов.

Диалог для разметки:
{dialogue_text}

Замени персональные данные на метки: [FIO], [LOC], [PHONE_NUM], [LK_NUM], [EMAIL]

Формат ответа (ТОЛЬКО JSON, БЕЗ ДРУГИХ ТЕКСТОВ):
[
  {{"role": "роль", "text": "текст"}},
  {{"role": "роль", "text": "текст"}}
]'''

def process_single_dialog(dialog, output_file, failed_file):
    """Обрабатывает один диалог"""
    
    # Формируем текст диалога
    dialogue_text = "\n".join([f"{msg['role']}: {msg['text']}" for msg in dialog['dialogue']])
    
    try:
        response = client.chat.completions.create(
            model="Qwen/Qwen3-8B-AWQ",
            messages=[{
                "role": "user", 
                "content": create_strict_prompt(dialogue_text)
            }],
            temperature=0.01,  # Минимальная случайность
            max_tokens=4000
        )
        
        result_text = response.choices[0].message.content
        print(f"Ответ получен, длина: {len(result_text)} символов")
        
        # Извлекаем JSON
        annotated_dialogue = extract_json_from_response(result_text)
        
        if annotated_dialogue and isinstance(annotated_dialogue, list):
            # Проверяем что все элементы имеют правильную структуру
            valid_structure = True
            for item in annotated_dialogue:
                if not isinstance(item, dict) or 'role' not in item or 'text' not in item:
                    valid_structure = False
                    break
            
            if valid_structure and len(annotated_dialogue) == len(dialog['dialogue']):
                # Создаем размеченный диалог
                annotated_dialog = dialog.copy()
                annotated_dialog['dialogue'] = annotated_dialogue
                annotated_dialog['annotated'] = True
                annotated_dialog['annotation_timestamp'] = time.time()
                
                # Сохраняем в основной файл
                save_to_jsonl(annotated_dialog, output_file)
                print(f"✓ Успешно размечен диалог ID: {dialog['id']}")
                return True
            else:
                print(f"✗ Неправильная структура в диалоге ID: {dialog['id']}")
        else:
            print(f"✗ Не удалось извлечь JSON для диалога ID: {dialog['id']}")
            
    except Exception as e:
        print(f"✗ Ошибка при обработке диалога ID: {dialog['id']}: {str(e)}")
    
    # Сохраняем информацию об ошибке
    save_failed_attempt(dialog, result_text if 'result_text' in locals() else str(e), failed_file)
    return False

def save_to_jsonl(dialog, filename):
    """Сохраняет каждый диалог как отдельную строку в JSONL файл"""
    with open(filename, 'a', encoding='utf-8') as f:
        json_line = json.dumps(dialog, ensure_ascii=False)
        f.write(json_line + '\n')

def save_failed_attempt(dialog, model_response, failed_file):
    """Сохраняет информацию о неудачной попытке"""
    failed_data = {
        'original_dialog': dialog,
        'model_response': model_response,
        'timestamp': time.time()
    }
    
    with open(failed_file, 'a', encoding='utf-8') as f:
        json_line = json.dumps(failed_data, ensure_ascii=False)
        f.write(json_line + '\n')

def load_existing_results(output_file):
    """Загружает уже обработанные ID из выходного файла"""
    processed_ids = set()
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            for line in f:
                dialog = json.loads(line.strip())
                processed_ids.add(str(dialog['id']))
    except FileNotFoundError:
        pass
    return processed_ids

def main():
    # Настройки
    input_file = "your_dataset.json"
    output_file = "annotated_dataset.jsonl"  # Теперь используем JSONL формат
    failed_file = "failed_annotations.jsonl"
    max_dialogs = 2000
    
    # Загрузка датасета
    with open(input_file, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    
    print(f"Загружено диалогов: {len(dataset)}")
    
    # Загружаем уже обработанные ID
    processed_ids = load_existing_results(output_file)
    print(f"Уже обработано: {len(processed_ids)} диалогов")
    
    # Фильтруем непроцессенные диалоги
    dialogs_to_process = []
    for dialog in dataset:
        if str(dialog['id']) not in processed_ids:
            dialogs_to_process.append(dialog)
        if len(dialogs_to_process) >= max_dialogs:
            break
    
    print(f"Будет обработано: {len(dialogs_to_process)} новых диалогов")
    
    success_count = 0
    fail_count = 0
    
    # Обработка каждого диалога
    for i, dialog in enumerate(dialogs_to_process):
        print(f"\n--- Обработка {i+1}/{len(dialogs_to_process)} (ID: {dialog['id']}) ---")
        
        success = process_single_dialog(dialog, output_file, failed_file)
        
        if success:
            success_count += 1
        else:
            fail_count += 1
        
        # Пауза между запросами
        time.sleep(1)
    
    print(f"\n=== ИТОГ ===")
    print(f"Успешно: {success_count}")
    print(f"Неудачно: {fail_count}")

if __name__ == "__main__":
    main()

-----------

import json
import time
from openai import OpenAI

# Настройка подключения к vLLM серверу
client = OpenAI(
    api_key="EMPTY",
    base_url="http://localhost:8000/v1"
)

def load_dataset(filename):
    """Загрузка датасета"""
    with open(filename, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_progress(annotated_data, filename):
    """Сохранение прогресса"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(annotated_data, f, ensure_ascii=False, indent=2)

def create_system_prompt():
    """Создание системного промпта с инструкциями"""
    return """Ты - ассистент для разметки персональных данных в диалогах технической поддержки.
    
ЗАДАЧА: Найди и замени все персональные данные в диалоге на соответствующие метки.

МЕТКИ ДЛЯ ЗАМЕНЫ:
- ФИО (полное или части) → [FIO]
- Место жительства (город, адрес) → [LOC] 
- Номер телефона → [PHONE_NUM]
- Email адрес → [EMAIL]

ПРАВИЛА:
1. Сохрани исходную структуру диалога
2. Заменяй ТОЛЬКО персональные данные, остальной текст оставляй без изменений
3. Используй метки точно как указано выше
4. Возвращай ТОЛЬКО размеченный диалог в формате JSON без дополнительных объяснений

ПРИМЕР РАЗМЕТКИ:
Вход: "Меня зовут Иван Иванов, телефон 89161234567, email ivan@mail.ru"
Выход: "Меня зовут [FIO], телефон [PHONE_NUM], email [EMAIL]"
"""

def annotate_dialogue(dialogue):
    """Разметка одного диалога с помощью модели"""
    
    # Формируем текст диалога для обработки
    dialogue_text = ""
    for message in dialogue:
        dialogue_text += f"{message['role']}: {message['text']}\n"
    
    user_prompt = f"""
    Разметь следующий диалог, заменив персональные данные на метки:
    
    {dialogue_text}
    
    Верни ТОЛЬКО размеченный диалог в том же формате (список словарей с role и text).
    """
    
    try:
        response = client.chat.completions.create(
            model="Qwen/Qwen3-8B-AWQ",
            messages=[
                {"role": "system", "content": create_system_prompt()},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,
            max_tokens=4000
        )
        
        result = response.choices[0].message.content
        
        # Парсим ответ модели (может быть JSON или текстом)
        try:
            # Пытаемся распарсить как JSON
            annotated_dialogue = json.loads(result)
            return annotated_dialogue
        except json.JSONDecodeError:
            # Если не JSON, пытаемся извлечь структуру другим способом
            print(f"Модель вернула не JSON. Ответ: {result}")
            return None
            
    except Exception as e:
        print(f"Ошибка при запросе к модели: {e}")
        return None

def main():
    # Настройки
    input_file = "your_dataset.json"  # Ваш исходный файл
    output_file = "annotated_dataset.json"  # Файл для результатов
    start_index = 0  # С какого диалога начать
    max_dialogs = 2000  # Сколько диалогов обработать
    
    # Загрузка датасета
    dataset = load_dataset(input_file)
    print(f"Загружено диалогов: {len(dataset)}")
    
    # Загрузка существующих результатов (если продолжаем)
    try:
        annotated_data = load_dataset(output_file)
        print(f"Найдены существующие результаты: {len(annotated_data)} диалогов")
    except FileNotFoundError:
        annotated_data = []
        print("Начинаем новую разметку...")
    
    # Определяем диапазон для обработки
    end_index = min(start_index + max_dialogs, len(dataset))
    
    # Обработка диалогов
    for i in range(start_index, end_index):
        original_dialog = dataset[i]
        print(f"Обработка диалога {i+1}/{len(dataset)} (ID: {original_dialog['id']})")
        
        # Разметка диалога
        annotated_dialogue = annotate_dialogue(original_dialog['dialogue'])
        
        if annotated_dialogue:
            # Создаем размеченный диалог
            annotated_dialog = original_dialog.copy()
            annotated_dialog['dialogue'] = annotated_dialogue
            annotated_dialog['annotated'] = True  # Помечаем как размеченный
            annotated_dialog['annotation_timestamp'] = time.time()
            
            annotated_data.append(annotated_dialog)
            
            # Сохраняем прогресс после каждого диалога
            save_progress(annotated_data, output_file)
            print(f"✓ Диалог {i+1} размечен и сохранен")
        else:
            print(f"✗ Ошибка разметки диалога {i+1}")
        
        # Небольшая пауза между запросами
        time.sleep(1)
    
    print(f"Готово! Обработано {len(annotated_data)} диалогов")
    print(f"Результаты сохранены в {output_file}")

if __name__ == "__main__":
    main()
