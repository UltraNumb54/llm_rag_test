# prepare.py
import os
import json
import pandas as pd
from razdel import tokenize

# === КОНСТАНТЫ ===
CSV_PATH = "annotations.csv"        # путь к вашему CSV
TEXTS_DIR = "texts/"                # папка с .txt файлами
OUTPUT_PATH = "train.conll"         # выходной файл в формате CoNLL

def char_spans_to_token_labels(text: str, entities: list) -> list:
    """
    Преобразует разметку по символам (start, end, label)
    в метки по токенам (BIO) с использованием razdel.
    """
    # 1. Размечаем каждый символ
    char_labels = ["O"] * len(text)
    for start, end, label in entities:
        if end > len(text):
            continue
        char_labels[start] = f"B-{label}"
        for i in range(start + 1, end):
            char_labels[i] = f"I-{label}"

    # 2. Токенизируем текст
    tokens = list(tokenize(text))
    token_labels = []

    for token in tokens:
        if token.start >= len(char_labels):
            token_labels.append("O")
        else:
            # Берём метку первого символа токена
            token_labels.append(char_labels[token.start])

    return [t.text for t in tokens], token_labels

def main():
    df = pd.read_csv(CSV_PATH)
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f_out:
        for _, row in df.iterrows():
            # Получаем путь к текстовому файлу
            filename = os.path.basename(row["text"])
            text_path = os.path.join(TEXTS_DIR, filename)

            if not os.path.exists(text_path):
                print(f"Файл не найден: {text_path}")
                continue

            # Читаем текст
            with open(text_path, "r", encoding="utf-8") as f_txt:
                text = f_txt.read()

            # Парсим аннотации
            try:
                ann_list = json.loads(row["label"])
            except:
                print(f"Ошибка в аннотациях для {filename}")
                continue

            entities = []
            for ann in ann_list:
                start = ann["start"]
                end = ann["end"]
                label = ann["labels"][0]  # например: "fio", "email", "position"
                entities.append((start, end, label))

            # Преобразуем в токены и метки
            tokens, labels = char_spans_to_token_labels(text, entities)

            # Записываем в CoNLL формат: токен + метка
            for token, label in zip(tokens, labels):
                f_out.write(f"{token} {label}\n")
            f_out.write("\n")  # пустая строка между документами

    print(f"✅ Данные подготовлены и сохранены в {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
